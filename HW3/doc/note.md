# 关于HW3框架的一些问题和要点

* rasterize.cpp中的rasterize_triangle函数中，关于计算用于插值的z的三段代码

  ``` c++
  	float Z = 1.0 / (alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w());
      float zp = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w();
      zp *= Z;
  ```

  * 第一行计算了在当前屏幕空间下该点在投影之前view空间中的z坐标（w分量为1时的z值）
  * **嗯思考了一下我决定当他放屁。z-buffer用于测试的z值应该是投影空间且齐次除法之后的z值，直接在齐次除法之后在投影空间线性插值即可**。当然纹理坐标这些都是要使用透视矫正插值的。
  * 计算重心坐标系数时给出的坐标值都应该是进行过齐次除法之后的。





## 关于bump mapping和displacement mapping

* 在进行凹凸贴图时，一般是会给出一张灰度图，用灰度来存储该点的高度（实际上凹凸也就是通过明暗表现出来的）。所以在计算Δh时，用的是纹理采样值。

  > 正规的凹凸纹理应该是只有一维参量的灰度图，而本课程为了框架使用的简便性而使用了一张 RGB 图作为凹凸纹理的贴图，因此需要指定一种规则将彩色投影到灰度，「恰好」选择了 norm即向量长度 而已。

  * 因为对法线偏移之后，还需要将其从切线空间转换回世界空间。切线空间由该点法线n、切线t，副切线b=n×t组成坐标轴。变换矩阵其实分别考虑点(1,0,0),(0,1,0),(0,0,1)变换之后对应xyz轴，便可得到TBN = [t b n]。坐标系转换都是这种方式。
  * 框架中的normal shader，实际上是在把法线范围转换至[0,1]之后，直接将其作为颜色，存储在表面纹理中，记录了法线信息。得到的算是法线图。
  * 而框架中bump mapping也是如此，在得到偏移之后的法线之后，直接将其作为颜色（因为没有转换范围，所以会有负数）。但按我的理解，应该还要用这个法线计算phong模型的光照吧，挺奇怪的。
    * 在对法线范围进行转换之后，其色调便接近与normal shader了。也可以看到明显的凹凸。

* 进行位移贴图时，比之凹凸多加了一步改变点的位置，然后用这个偏移之后的法线和点位置计算phong光照
